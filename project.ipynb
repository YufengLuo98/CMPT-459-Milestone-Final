{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB, MultinomialNB\n",
    "from imblearn.combine import SMOTEENN \n",
    "from imblearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(\"data/cases_2021_train_processed.xlsx\")\n",
    "test_data = pd.read_excel(\"data/cases_2021_test_processed_unlabelled.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2: Mapping the features\n",
    "\n",
    "1. Converted uneccesary float values to integer\n",
    "2. Categorical values that are binary in nature converted to 0's and 1's\n",
    "3. One-hot encoding done on 'province' and 'country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'Confirmed', 'Deaths', 'Recovered', 'Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[cols] = train_data[cols].apply(pd.to_numeric, downcast='integer', axis=1)\n",
    "test_data[cols] = test_data[cols].apply(pd.to_numeric, downcast='integer', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_groups = {'deceased': 0, 'hospitalized': 1,'nonhospitalized': 2}\n",
    "outcome_groups_inverse = {0: 'deceased', 1: 'hospitalized', 2: 'nonhospitalized'}\n",
    "sex = {'male': 0, 'female': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['outcome_group'] = train_data['outcome_group'].map(outcome_groups)\n",
    "train_data['sex'] = train_data['sex'].map(sex)\n",
    "train_data['province'] = train_data['province'].fillna('Philippines')\n",
    "train_data['chronic_disease_binary'] = train_data['chronic_disease_binary'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['sex'] = test_data['sex'].map(sex)\n",
    "test_data['province'] = test_data['province'].fillna('Philippines')\n",
    "test_data['chronic_disease_binary'] = test_data['chronic_disease_binary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13241\n",
       "2     2974\n",
       "0      997\n",
       "Name: outcome_group, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['outcome_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['province', 'country']\n",
    "train_data = pd.get_dummies(train_data, columns=dummy_cols)\n",
    "test_data = pd.get_dummies(test_data, columns=dummy_cols)\n",
    "\n",
    "# Need to make sure the columns are the same in train and test data\n",
    "test_data = test_data.reindex(columns=train_data.columns, fill_value=0)\n",
    "test_data.drop('outcome_group', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['date_confirmation_int'] = train_data['date_confirmation'].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "test_data['date_confirmation_int'] = test_data['date_confirmation'].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "train_data.drop(['date_confirmation', 'Confirmed', 'Deaths', 'Recovered', 'Active'], axis=1, inplace=True)\n",
    "test_data.drop(['date_confirmation', 'Confirmed', 'Deaths', 'Recovered', 'Active'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the data using SMOTE (generates new data similar to minority class data)\n",
    "X = train_data.drop('outcome_group', axis=1)\n",
    "y = train_data['outcome_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13241\n",
       "2     2974\n",
       "0      997\n",
       "Name: outcome_group, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The counts of each class labels are now the same\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassificationResults(model):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        all_labels = all_labels + list(y_test)\n",
    "        all_predictions = all_predictions + list(predictions)\n",
    "\n",
    "    report = classification_report(all_labels, all_predictions)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmissionFile(model, filename):\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(test_data)\n",
    "    submission = pd.DataFrame({'Prediction': predictions})\n",
    "    submission.index.name = 'Id'\n",
    "    submission.to_csv('submissions/{filename}'.format(filename=filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53       997\n",
      "           1       0.98      1.00      0.99     13241\n",
      "           2       0.89      0.84      0.87      2974\n",
      "\n",
      "    accuracy                           0.94     17212\n",
      "   macro avg       0.80      0.79      0.80     17212\n",
      "weighted avg       0.94      0.94      0.94     17212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Random Forest\n",
    "params = {\n",
    "    \"randomforestclassifier__max_depth\": [i for i in range(5, 50, 5)],\n",
    "    \"randomforestclassifier__min_samples_split\": [i for i in range(2, 12, 2)],\n",
    "    \"randomforestclassifier__min_samples_leaf\": [i for i in range(1, 6, 1)],\n",
    "}\n",
    "random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=15, min_samples_leaf=2, min_samples_split=4, class_weight='balanced'))\n",
    "search = GridSearchCV(random_forest, params, scoring='f1_macro')\n",
    "# Best params: max_depth=15, min_samples_leaf=2, min_samples_split=4\n",
    "#search.fit(X, y)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)\n",
    "printClassificationResults(random_forest)\n",
    "createSubmissionFile(random_forest, 'random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.37      0.48       997\n",
      "           1       0.98      1.00      0.99     13241\n",
      "           2       0.85      0.93      0.89      2974\n",
      "\n",
      "    accuracy                           0.95     17212\n",
      "   macro avg       0.84      0.76      0.79     17212\n",
      "weighted avg       0.94      0.95      0.94     17212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Neural Network\n",
    "neural_network = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=1))\n",
    "printClassificationResults(neural_network)\n",
    "createSubmissionFile(neural_network, 'neural_network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing XGBoost\n",
    "xgboost = make_pipeline(StandardScaler(), XGBClassifier(use_label_encoder=False))\n",
    "printClassificationResults(xgboost)\n",
    "createSubmissionFile(xgboost, 'xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.19      0.32       997\n",
      "           1       0.98      1.00      0.99     13241\n",
      "           2       0.82      0.96      0.89      2974\n",
      "\n",
      "    accuracy                           0.95     17212\n",
      "   macro avg       0.91      0.72      0.73     17212\n",
      "weighted avg       0.95      0.95      0.93     17212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Support Vector Machine\n",
    "svlinear = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "printClassificationResults(svmachine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.08      0.15       997\n",
      "           1       0.97      0.99      0.98     13241\n",
      "           2       0.80      0.96      0.88      2974\n",
      "\n",
      "    accuracy                           0.93     17212\n",
      "   macro avg       0.84      0.68      0.67     17212\n",
      "weighted avg       0.93      0.93      0.92     17212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Naive Bayes\n",
    "mnb = make_pipeline(MinMaxScaler(), MultinomialNB())\n",
    "printClassificationResults(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ff4c835d7956487bba13277bf340d67efa161ba50aa68448d8213de87c08323"
  },
  "kernelspec": {
   "display_name": "CMPT-353",
   "language": "python",
   "name": "cmpt-353"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
