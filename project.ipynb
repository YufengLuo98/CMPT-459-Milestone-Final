{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, train\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn\n",
    "\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(\"data/cases_2021_train_processed.xlsx\")\n",
    "test_data = pd.read_excel(\"data/cases_2021_test_processed_unlabelled.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. Convert unnecessary float values to integers\n",
    "2. Convert binary categorical features to 0's and 1's\n",
    "3. Use one-hot encoding for 'province' and 'country' columns\n",
    "4. Convert 'date_confimation' to integer\n",
    "5. Remove 'Confirmed', 'Active', 'Deaths', and 'Recovered', columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast features with floats to integers\n",
    "cols = ['age', 'Confirmed', 'Deaths', 'Recovered', 'Active']\n",
    "train_data[cols] = train_data[cols].apply(pd.to_numeric, downcast='integer', axis=1)\n",
    "test_data[cols] = test_data[cols].apply(pd.to_numeric, downcast='integer', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mappings for categorical variables\n",
    "outcome_groups = {'deceased': 0, 'hospitalized': 1,'nonhospitalized': 2}\n",
    "sex = {'male': 0, 'female': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map outcome_group to 0, 1, 2\n",
    "train_data['outcome_group'] = train_data['outcome_group'].map(outcome_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sex to 0, 1\n",
    "train_data['sex'] = train_data['sex'].map(sex)\n",
    "test_data['sex'] = test_data['sex'].map(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in province for Philippines\n",
    "train_data['province'] = train_data['province'].fillna('Philippines')\n",
    "test_data['province'] = test_data['province'].fillna('Philippines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert chronic_disease_binary to 0, 1\n",
    "train_data['chronic_disease_binary'] = train_data['chronic_disease_binary'].astype(int)\n",
    "test_data['chronic_disease_binary'] = test_data['chronic_disease_binary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy columns for province and country\n",
    "dummy_cols = ['province', 'country']\n",
    "train_data = pd.get_dummies(train_data, columns=dummy_cols)\n",
    "test_data = pd.get_dummies(test_data, columns=dummy_cols)\n",
    "\n",
    "# Need to make sure the columns are the same in train and test data\n",
    "test_data = test_data.reindex(columns=train_data.columns, fill_value=0)\n",
    "test_data.drop('outcome_group', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_confirmation to int\n",
    "train_data['date_confirmation_int'] = train_data['date_confirmation'].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "test_data['date_confirmation_int'] = test_data['date_confirmation'].dt.strftime(\"%Y%m%d\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary features\n",
    "train_data.drop(['date_confirmation', 'Confirmed', 'Deaths', 'Recovered', 'Active'], axis=1, inplace=True)\n",
    "test_data.drop(['date_confirmation', 'Confirmed', 'Deaths', 'Recovered', 'Active'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of outcome groups\n",
    "plt.bar(train_data['outcome_group'].unique(), train_data['outcome_group'].value_counts())\n",
    "plt.locator_params(axis='x', nbins=4)\n",
    "plt.title('Distribution of outcome groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('outcome_group', axis=1)\n",
    "y = train_data['outcome_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model/models using 5-fold validation, and print the validation scores.\n",
    "def printClassificationResults(models):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        ensemble_predictions = pd.DataFrame(index=range(y_test.shape[0]))\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            model = models[i]\n",
    "            model.fit(X_train, y_train)\n",
    "            ensemble_predictions[i] = model.predict(X_test)\n",
    "\n",
    "        predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "        all_labels = all_labels + list(y_test)\n",
    "        all_predictions = all_predictions + list(predictions)\n",
    "\n",
    "    report = classification_report(all_labels, all_predictions)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model/models using 5-fold validation, and return the macro f1-score\n",
    "def getMacroF1(models):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        ensemble_predictions = pd.DataFrame(index=range(y_test.shape[0]))\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            model = models[i]\n",
    "            model.fit(X_train, y_train)\n",
    "            ensemble_predictions[i] = model.predict(X_test)\n",
    "\n",
    "        predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "        all_labels = all_labels + list(y_test)\n",
    "        all_predictions = all_predictions + list(predictions)\n",
    "\n",
    "    report = classification_report(all_labels, all_predictions, output_dict=True)\n",
    "    return report['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model/models on the full training dataset, and create a submission file with the predictions for the test dataset\n",
    "def createSubmissionFile(models, filename):\n",
    "    ensemble_predictions = pd.DataFrame(index=range(test_data.shape[0]))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        model.fit(X, y)\n",
    "        ensemble_predictions[i] = model.predict(test_data)\n",
    "\n",
    "    predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "    submission = pd.DataFrame({'Prediction': predictions})\n",
    "    submission.index.name = 'Id'\n",
    "    submission.to_csv('submissions/{filename}'.format(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "**Best params:**\n",
    " - *max_depth* = 14\n",
    " - *max_samples* = 0.56\n",
    " - *min_samples_leaf* = 1\n",
    " - *min_samples_split* = 5\n",
    " - *class_weight* = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"randomforestclassifier__max_depth\": [i for i in range(13, 16)],\n",
    "    \"randomforestclassifier__min_samples_split\": [i for i in range(5, 8)],\n",
    "    \"randomforestclassifier__min_samples_leaf\": [i for i in range(1, 3)],\n",
    "    'randomforestclassifier__max_samples': [i/100 for i in range(33, 38)]\n",
    "}\n",
    "\n",
    "random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=14, max_samples=0.56, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1))\n",
    "printClassificationResults([random_forest])\n",
    "createSubmissionFile([random_forest], 'random_forest.csv')\n",
    "\n",
    "#search = GridSearchCV(random_forest, params, scoring='f1_macro')\n",
    "#search.fit(X, y)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot macro F1-score for various values of max_samples\n",
    "plotX = [i/100 for i in range(10, 101, 10)]\n",
    "plotY = []\n",
    "for max_samples in plotX:\n",
    "    random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=14, max_samples=max_samples, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1))\n",
    "    macroF1 = getMacroF1([random_forest])\n",
    "    plotY.append(macroF1)   \n",
    "\n",
    "plt.plot(plotX, plotY)\n",
    "plt.xlabel('Max_Samples')\n",
    "plt.ylabel('Macro F1-Score')\n",
    "plt.title('Random Forest Macro F1-Score vs Max_Samples')\n",
    "plt.savefig('plots/random_forest_max_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot macro F1-score for various values of max_depth\n",
    "plotX = [i for i in range(5, 51, 5)]\n",
    "plotY = []\n",
    "for max_depth in plotX:\n",
    "    random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=max_depth, max_samples=0.56, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1))\n",
    "    macroF1 = getMacroF1([random_forest])\n",
    "    plotY.append(macroF1)   \n",
    "\n",
    "plt.plot(plotX, plotY)\n",
    "plt.xlabel('Max_Depth')\n",
    "plt.ylabel('Macro F1-Score')\n",
    "plt.title('Random Forest Macro F1-Score vs Max_Depth')\n",
    "plt.savefig('plots/random_forest_max_depth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "**Best params:**\n",
    " - *eta* = 0.3222\n",
    " - *max_depth* = 4\n",
    " - *subsample* = 0.7\n",
    " - *min_child_weight* = 5\n",
    " - *gamma* = 1\n",
    " - *colsample_bytree* = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default hyperparameters for XGBoost\n",
    "xgboost = make_pipeline(StandardScaler(), XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n",
    "printClassificationResults([xgboost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for optimal hyperparameters (commented out due to long runtime)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "xg_params = {\n",
    "    'xgbclassifier__min_child_weight': [3, 5, 7],\n",
    "    'xgbclassifier__gamma': [0.6, 1, 1.3],\n",
    "    'xgbclassifier__subsample': [0.3,0.5, 0.7],\n",
    "    'xgbclassifier__colsample_bytree': [0.6, 0.8],\n",
    "    'xgbclassifier__max_depth': [4, 5],\n",
    "    'xgbclassifier__eta': [0.1, 0.3, 0.35]\n",
    "}\n",
    "\n",
    "#xgboost_cv = make_pipeline(StandardScaler(), XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n",
    "#xgboost_grid = GridSearchCV(xgboost_cv, xg_params) \n",
    "#xgboost_random = RandomizedSearchCV(xgboost_cv, xg_params, refit=True, n_iter=10)\n",
    "#xgboost_random.fit(X,y)\n",
    "#print(xgboost_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal hyperparameters for XGBoost\n",
    "xgboost_cv = make_pipeline(StandardScaler(), XGBClassifier(eta=0.3222,max_depth=4,subsample=0.7,min_child_weight=5, gamma = 1, colsample_bytree=0.6,use_label_encoder=False, eval_metric='mlogloss'))\n",
    "printClassificationResults([xgboost_cv]) \n",
    "createSubmissionFile([xgboost_cv], 'xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "**Best params:**\n",
    " - *activation* = 'relu'\n",
    " - *solver* = 'adam'\n",
    " - *max_iter* = 500\n",
    " - *hidden_layer_sizes* = (25,50,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the data by doubling the data entries for the 'deceased' class\n",
    "balanced = pd.concat([train_data, train_data[train_data['outcome_group']==0].sample(500, replace=True)])\n",
    "X = balanced.drop('outcome_group', axis=1)\n",
    "y = balanced['outcome_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an additional feature to group together similar ages\n",
    "X['age_group'] = np.ceil(X['age'] / 10)\n",
    "test_data['age_group'] = np.ceil(test_data['age'] / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal hyperparameters for Bagging Classifier of MLP Classifiers\n",
    "neural_network = make_pipeline(StandardScaler(),\n",
    "                               MLPClassifier(activation='relu', solver='adam', max_iter=500, early_stopping=True,\n",
    "                                             hidden_layer_sizes = (25,50,25)))\n",
    "bagging = BaggingClassifier(base_estimator = neural_network, n_estimators=5, random_state=0)\n",
    "\n",
    "printClassificationResults([bagging])\n",
    "createSubmissionFile([bagging], 'neural_network.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set predictions the mode prediction from the random forest, xgboost, and neural network models\n",
    "rf = pd.read_csv('submissions/random_forest.csv')\n",
    "xg = pd.read_csv('submissions/xgboost.csv')\n",
    "nn = pd.read_csv('submissions/neural_network.csv')\n",
    "ensemble_predictions = pd.DataFrame(data={'rf': rf['Prediction'], 'xg': xg['Prediction'], 'nn': nn['Prediction']})\n",
    "predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "submission = pd.DataFrame({'Prediction': predictions})\n",
    "submission.index.name = 'Id'\n",
    "submission.to_csv('submissions/ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ff4c835d7956487bba13277bf340d67efa161ba50aa68448d8213de87c08323"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
