{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, train\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn\n",
    "\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(\"data/cases_2021_train_processed.xlsx\")\n",
    "test_data = pd.read_excel(\"data/cases_2021_test_processed_unlabelled.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2: Mapping the features\n",
    "\n",
    "1. Converted uneccesary float values to integer\n",
    "2. Categorical values that are binary in nature converted to 0's and 1's\n",
    "3. One-hot encoding done on 'province' and 'country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast features with floats to integers\n",
    "cols = ['age', 'Confirmed', 'Deaths', 'Recovered', 'Active']\n",
    "train_data[cols] = train_data[cols].apply(pd.to_numeric, downcast='integer', axis=1)\n",
    "test_data[cols] = test_data[cols].apply(pd.to_numeric, downcast='integer', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mappings for categorical variables\n",
    "outcome_groups = {'deceased': 0, 'hospitalized': 1,'nonhospitalized': 2}\n",
    "sex = {'male': 0, 'female': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map outcome_group to 0, 1, 2\n",
    "train_data['outcome_group'] = train_data['outcome_group'].map(outcome_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sex to 0, 1\n",
    "train_data['sex'] = train_data['sex'].map(sex)\n",
    "test_data['sex'] = test_data['sex'].map(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in province for Philippines\n",
    "train_data['province'] = train_data['province'].fillna('Philippines')\n",
    "test_data['province'] = test_data['province'].fillna('Philippines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert chronic_disease_binary to 0, 1\n",
    "train_data['chronic_disease_binary'] = train_data['chronic_disease_binary'].astype(int)\n",
    "test_data['chronic_disease_binary'] = test_data['chronic_disease_binary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy columns for province and country\n",
    "dummy_cols = ['province', 'country']\n",
    "train_data = pd.get_dummies(train_data, columns=dummy_cols)\n",
    "test_data = pd.get_dummies(test_data, columns=dummy_cols)\n",
    "\n",
    "# Need to make sure the columns are the same in train and test data\n",
    "test_data = test_data.reindex(columns=train_data.columns, fill_value=0)\n",
    "test_data.drop('outcome_group', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_confirmation to int\n",
    "train_data['date_confirmation_int'] = train_data['date_confirmation'].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "test_data['date_confirmation_int'] = test_data['date_confirmation'].dt.strftime(\"%Y%m%d\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary features\n",
    "train_data.drop(['date_confirmation', 'Confirmed', 'Deaths', 'Recovered', 'Active'], axis=1, inplace=True)\n",
    "test_data.drop(['date_confirmation', 'Confirmed', 'Deaths', 'Recovered', 'Active'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of outcome groups\n",
    "plt.bar(train_data['outcome_group'].unique(), train_data['outcome_group'].value_counts())\n",
    "plt.locator_params(axis='x', nbins=4)\n",
    "plt.title('Distribution of outcome groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('outcome_group', axis=1)\n",
    "y = train_data['outcome_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model/models using 5-fold validation, and print the validation scores.\n",
    "def printClassificationResults(models):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        ensemble_predictions = pd.DataFrame(index=range(y_test.shape[0]))\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            model = models[i]\n",
    "            model.fit(X_train, y_train)\n",
    "            ensemble_predictions[i] = model.predict(X_test)\n",
    "\n",
    "        predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "        all_labels = all_labels + list(y_test)\n",
    "        all_predictions = all_predictions + list(predictions)\n",
    "\n",
    "    report = classification_report(all_labels, all_predictions)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model/models using 5-fold validation, and return the macro f1-score\n",
    "def getMacroF1(models):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        ensemble_predictions = pd.DataFrame(index=range(y_test.shape[0]))\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            model = models[i]\n",
    "            model.fit(X_train, y_train)\n",
    "            ensemble_predictions[i] = model.predict(X_test)\n",
    "\n",
    "        predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "        all_labels = all_labels + list(y_test)\n",
    "        all_predictions = all_predictions + list(predictions)\n",
    "\n",
    "    report = classification_report(all_labels, all_predictions, output_dict=True)\n",
    "    return report['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model/models on the full training dataset, and create a submission file with the predictions for the test dataset\n",
    "def createSubmissionFile(models, filename):\n",
    "    ensemble_predictions = pd.DataFrame(index=range(test_data.shape[0]))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        model.fit(X, y)\n",
    "        ensemble_predictions[i] = model.predict(test_data)\n",
    "\n",
    "    predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "    submission = pd.DataFrame({'Prediction': predictions})\n",
    "    submission.index.name = 'Id'\n",
    "    submission.to_csv('submissions/{filename}'.format(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Best params: max_depth=14, max_samples=0.56, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"randomforestclassifier__max_depth\": [i for i in range(13, 16)],\n",
    "    \"randomforestclassifier__min_samples_split\": [i for i in range(5, 8)],\n",
    "    \"randomforestclassifier__min_samples_leaf\": [i for i in range(1, 3)],\n",
    "    'randomforestclassifier__max_samples': [i/100 for i in range(33, 38)]\n",
    "}\n",
    "\n",
    "random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=14, max_samples=0.56, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1))\n",
    "printClassificationResults([random_forest])\n",
    "createSubmissionFile([random_forest], 'random_forest.csv')\n",
    "\n",
    "#search = GridSearchCV(random_forest, params, scoring='f1_macro')\n",
    "#search.fit(X, y)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot macro F1-score for various values of max_samples\n",
    "plotX = [i/100 for i in range(10, 101, 10)]\n",
    "plotY = []\n",
    "for max_samples in plotX:\n",
    "    random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=14, max_samples=max_samples, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1))\n",
    "    macroF1 = getMacroF1([random_forest])\n",
    "    plotY.append(macroF1)   \n",
    "\n",
    "plt.plot(plotX, plotY)\n",
    "plt.xlabel('Max_Samples')\n",
    "plt.ylabel('Macro F1-Score')\n",
    "plt.title('Random Forest Macro F1-Score vs Max_Samples')\n",
    "plt.savefig('plots/random_forest_max_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot macro F1-score for various values of max_depth\n",
    "plotX = [i for i in range(5, 51, 5)]\n",
    "plotY = []\n",
    "for max_depth in plotX:\n",
    "    random_forest = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=max_depth, max_samples=0.56, min_samples_leaf=1, min_samples_split=5, class_weight='balanced', random_state=1))\n",
    "    macroF1 = getMacroF1([random_forest])\n",
    "    plotY.append(macroF1)   \n",
    "\n",
    "plt.plot(plotX, plotY)\n",
    "plt.xlabel('Max_Depth')\n",
    "plt.ylabel('Macro F1-Score')\n",
    "plt.title('Random Forest Macro F1-Score vs Max_Depth')\n",
    "plt.savefig('plots/random_forest_max_depth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing XGBoost\n",
    "\n",
    "# Base model\n",
    "xgboost = make_pipeline(StandardScaler(), XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n",
    "printClassificationResults([xgboost])\n",
    "# createSubmissionFile(xgboost, 'xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "### tuning XGBoost\n",
    "xg_params = {\n",
    "        'xgbclassifier__min_child_weight': [3, 5, 7],\n",
    "        'xgbclassifier__gamma': [0.6, 1, 1.3],\n",
    "        'xgbclassifier__subsample': [0.3,0.5, 0.7],\n",
    "        'xgbclassifier__colsample_bytree': [0.6, 0.8],\n",
    "        'xgbclassifier__max_depth': [4, 5],\n",
    "        'xgbclassifier__eta': [0.1, 0.3, 0.35]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching parameters\n",
    "\n",
    "# Best params: eta=0.3222, max_depth=4, subsample=0.7, min_child_weight=5, gamma=1, colsample_bytree=0.6\n",
    "xgboost_cv = make_pipeline(StandardScaler(), XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n",
    "xgboost_grid = GridSearchCV(xgboost_cv, xg_params) \n",
    "# xgboost_random = RandomizedSearchCV(xgboost_cv, xg_params, refit=True, n_iter=10)\n",
    "xgboost_random.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cv_results = pd.DataFrame(xgboost_random.cv_results_)\n",
    "xg_cv_results.to_csv('results/xgboost_grid_tuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "\n",
    "xgboost_cv = make_pipeline(StandardScaler(), XGBClassifier(eta=0.3222,max_depth=4,subsample=0.7,min_child_weight=5, gamma = 1, colsample_bytree=0.6,use_label_encoder=False, eval_metric='mlogloss'))\n",
    "printClassificationResults([xgboost_cv]) \n",
    "createSubmissionFile([xgboost_cv], 'xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Support Vector Machine\n",
    "\n",
    "#baseline scores\n",
    "svlinear = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "printClassificationResults([svlinear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing SVM with GridsearchCV\n",
    "# Kernel\n",
    "# C - penalty, higher will create larger margins\n",
    "# Gamma - high gamma will cause overfitting\n",
    "\n",
    "# SVM best params for 'svc__C':[0.1,1,10],'svc__kernel':['linear'],'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "# {'svc__C': 1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
    "\n",
    "# svm_tuned = make_pipeline(StandardScaler(), SVC(C=0.5, gamma=1, kernel='linear', class_weight='balanced'))\n",
    "# svm_grid = GridSearchCV(svm_cv, svm_params)\n",
    "# printClassificationResults([svm_tuned])\n",
    "# createSubmissionFile(svm_tuned, 'linear_svm.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV on SVM\n",
    "# svm_cv = make_pipeline(StandardScaler(), SVC())\n",
    "# svm_params = { 'svc__C':[0.1,0.5,1, 1.5, 2],'svc__kernel':['linear'],'svc__gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'svc__class_weight':['balanced']}\n",
    "# svm_grid = GridSearchCV(svm_cv, svm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_cv_results = pd.DataFrame(svm_grid.cv_results_)\n",
    "# svm_cv_results.to_csv('results/support_vector_machine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually balance minorty class\n",
    "balanced = pd.concat([train_data, train_data[train_data['outcome_group']==0]])\n",
    "\n",
    "X = balanced.drop('outcome_group', axis=1)\n",
    "y = balanced['outcome_group']\n",
    "X['age_group'] = np.ceil(X['age'] / 10)\n",
    "test_data['age_group'] = np.ceil(test_data['age'] / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Bagging Classifier of MLP Classifiers\n",
    "neural_network = make_pipeline(StandardScaler(),\n",
    "                               MLPClassifier(activation='relu', solver='adam', max_iter=500, early_stopping=True))\n",
    "bagging = BaggingClassifier(base_estimator = neural_network, n_estimators=5, random_state=0)\n",
    "\n",
    "printClassificationResults([bagging])\n",
    "createSubmissionFile([bagging], 'neural_network.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.read_csv('submissions/random_forest.csv')\n",
    "xg = pd.read_csv('submissions/xgboost.csv')\n",
    "nn = pd.read_csv('submissions/neural_network.csv')\n",
    "ensemble_predictions = pd.DataFrame(data={'rf': rf['Prediction'], 'xg': xg['Prediction'], 'nn': nn['Prediction']})\n",
    "predictions = ensemble_predictions.mode(axis=1)[0].astype(int)\n",
    "submission = pd.DataFrame({'Prediction': predictions})\n",
    "submission.index.name = 'Id'\n",
    "submission.to_csv('submissions/ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ff4c835d7956487bba13277bf340d67efa161ba50aa68448d8213de87c08323"
  },
  "kernelspec": {
   "display_name": "CMPT-353",
   "language": "python",
   "name": "cmpt-353"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
